---
title: "Lab 4: Deploying a LangGraph Agent with FastAPI, AWS Lambda, and Streamlit"
weight: 4
---

# Deploying a `LangGraph` Agent with `FastAPI`, AWS `Lambda`, and `Streamlit`

## Introduction to FastAPI
`FastAPI` is a modern, high-performance web framework for building APIs with Python. It's designed to be easy to use while offering automatic API documentation, data validation, and serialization capabilities.

In the context of this lab, `FastAPI` provides a convenient way to create an API wrapper around the `LangGraph` agent, making it accessible via HTTP requests.

## Deployment Architecture

The deployment architecture consists of three main components:
### 1. LangGraph Agent with FastAPI Interface

The core of the system is a `FastAPI` application that wraps the `LangGraph` agent. This application exposes endpoints that clients can use to interact with the agent, particularly the `/generate-itinerary` endpoint that receives user messages and returns itinerary information.

### 2. AWS `Lambda` and `API Gateway` Deployment
The `FastAPI` application is containerized and deployed as an AWS `Lambda` function with `API Gateway` integration. This serverless approach allows the system to scale automatically based on demand.

### The deployment process includes:

- Building and pushing a Docker container to Amazon Elastic Container Registry (ECR)
- Creating a Lambda function using the container image
- Setting up API Gateway with Lambda integration
- Configuring API key authentication for security

### 3. Streamlit User Interface
The final component is a `Streamlit` application that provides a user-friendly interface for interacting with the agent. 

![ui](/amazon-bedrock-modular-overview/static/080-agents-with-langgraph/084-deploy-agent/ui.png)
![chat](/amazon-bedrock-modular-overview/static/080-agents-with-langgraph/084-deploy-agent/chat.png)

## Steps to run:

1. Make sure you have the virtual environment activated. Run the command below to deploy the agent. This command runs the `build_and_push.sh` script to build the docker image and push it to `Amazon Elastic Container Registry (ECR)`. Next, it creates a new Lambda function using the container image. It also creates an HTTP API (API Gateway v2) to invoke the Lambda function. The API Gateway URL is printed at the end of the script. This command also creates an API key for securing the API with a usage plan.

    ```bash
    python deploy.py --function-name <name-of-your-lambda-function> --role-arn <your-iam-role-name> --api-gateway
    ```

    The IAM role you need to use for the AWS Lambda needs to have Amazon Bedrock access (for example via [AmazonBedrockFullAccess](https://docs.aws.amazon.com/aws-managed-policy/latest/reference/AmazonBedrockFullAccess.html)) to use the models available via Amazon Bedrock and the models need to be enabled within your AWS account, see instructions available [here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html).

2. You can test the API using `curl` or `Postman`. The API Gateway URL is printed at the end of the script. You can use this URL to test the API. The API key is also printed at the end of the script. You can use this API key to test the API.

    ```bash
    curl -X POST -H "Content-Type: application/json" -d '{"user_message":"Plan a trip to Paris"}' https://<YOUR-API-KEY>.execute-api.us-east-1.amazonaws.com/prod/generate-itinerary
    ```

3. **Launch the streamlit app**: Run the command below to launch the streamlit app. This app will use the API Gateway URL to generate a response using the agent. The app will also show the response generated by the LangGraph agent.

    ```bash
    streamlit run chatbot.py -- --api-server-url https://<YOUR-API-KEY>.execute-api.us-east-1.amazonaws.com/prod/generate-itinerary
    ```